# ERGM / Maximum-Entropy: Solver Comparison with NEMtropy

Reproducible experiment for the **Complex Network Analysis** course — [2nd Level Master in Data Science and Statistical Learning (MD2SL)](https://md2sl-eng.imtlucca.it/), IMT School for Advanced Studies Lucca & University of Florence.

## Background

Maximum-entropy models (Exponential Random Graph Models, ERGM) provide statistically principled *null models* for real networks by enforcing observed constraints (e.g. degree sequence). Estimating the Lagrange multipliers requires maximising the log-likelihood numerically.

Vallarano *et al.* (2021) compare three solver families implemented in the **NEMtropy** library:

| Method | Description |
|---|---|
| `newton` | Newton-Raphson with full Hessian |
| `quasinewton` | Newton-Raphson with diagonal Hessian (approx.) |
| `fixed-point` | Fixed-point iteration |

Models tested:
- **UBCM** – Undirected Binary Configuration Model (`cm_exp`)
- **DBCM** – Directed Binary Configuration Model (`dcm_exp`)

## Methodology

1. **Zachary's Karate Club** (n=34, m=78): UBCM solved with each method (3 runs, random seeds).
2. **Synthetic G(n, p=0.05) networks**: Erdős–Rényi undirected (UBCM) and directed (DBCM) graphs with n ∈ {50, 100, 200}, 3 runs per method × size combination.
3. For each run: **wall-clock runtime** and **maximum relative error** on the reconstructed degree constraints vs. the observed ones.

The relative error is defined as:

$$\varepsilon = \max_{i:\, k_i > 0} \frac{|k_i - \hat{k}_i|}{k_i}$$

where $k_i$ is the observed degree and $\hat{k}_i$ the expected degree under the fitted model.

## Results

All three solvers converge with relative errors of order $10^{-8}$–$10^{-15}$ (DBCM) and $10^{-8}$–$10^{-10}$ (UBCM, newton/quasinewton). The `fixed-point` method on small sparse networks may exhibit less precise convergence for UBCM.

| Network | Model | Method | n | Mean runtime (s) | Max rel. error |
|---|---|---|---|---|---|
| Karate Club | UBCM | newton | 34 | 0.752 | 6.3 × 10⁻⁹ |
| Karate Club | UBCM | quasinewton | 34 | 0.088 | 2.6 × 10⁻⁸ |
| Karate Club | UBCM | fixed-point | 34 | 0.154 | 3.3 × 10⁻⁹ |
| G(n,p) undir. | UBCM | newton | 200 | 0.003 | 1.8 × 10⁻⁸ |
| G(n,p) undir. | UBCM | quasinewton | 200 | 0.020 | 2.7 × 10⁻⁸ |
| G(n,p) undir. | UBCM | fixed-point | 200 | 0.002 | 2.2 × 10⁻⁹ |
| G(n,p) dir. | DBCM | newton | 200 | 0.024 | 5.7 × 10⁻⁷ |
| G(n,p) dir. | DBCM | quasinewton | 200 | 0.013 | 9.6 × 10⁻¹² |
| G(n,p) dir. | DBCM | fixed-point | 200 | 0.014 | 6.1 × 10⁻¹⁰ |

> Full table: `results/tables/benchmark.csv` (generated by the script).

## Quickstart

```bash
# 1) Create virtualenv
python3.11 -m venv .venv
source .venv/bin/activate          # Linux/macOS
# .\.venv\Scripts\Activate.ps1     # Windows PowerShell

# 2) Install dependencies
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

# 3) Run experiment
python src/experiment.py --outdir results --seed 42 --runs 3
```

### Fallback (if `pip install NEMtropy` fails)

```bash
pip install "git+https://github.com/nicoloval/NEMtropy.git"
# or: conda env create -f environment.yml && conda activate cna-nemtropy
```

## Output

The script produces:

```
results/
├── figures/
│   ├── runtime_vs_n.png
│   ├── karate_runtime_methods.png
│   └── error_heatmap.png
├── tables/
│   ├── benchmark.csv
│   └── metadata.json
└── samples/                       # (optional, with --sample_n > 0)
```

## Reproducibility

- Global seed: `--seed 42` (default). NumPy's RNG derives internal seeds for each run.
- `metadata.json` records Python version, platform and parameters.
- To freeze dependency versions: `pip freeze > pip_freeze.txt`

## Repository structure

```
.
├── README.md
├── requirements.txt
├── environment.yml
├── .gitignore
├── src/
│   └── experiment.py              # End-to-end script
├── data/
│   ├── download_data.sh           # Downloads MovieLens 100K (optional)
│   └── raw/                       # Raw data (not committed)
└── results/
    ├── figures/
    ├── tables/
    └── samples/
```

## References

1. Vallarano, N., Bruno, M., Marchese, E., Trapani, G., Saracco, F., Cimini, G., Zanon, M. & Squartini, T. (2021). *Fast and scalable likelihood maximization for Exponential Random Graph Models with local constraints.* Scientific Reports **11**, 15227. [doi:10.1038/s41598-021-93830-4](https://doi.org/10.1038/s41598-021-93830-4) — [arXiv:2101.12625](https://arxiv.org/abs/2101.12625)
2. Squartini, T. & Garlaschelli, D. (2011). *Analytical maximum-likelihood method to detect patterns in real networks.* New Journal of Physics **13**, 083001. [doi:10.1088/1367-2630/13/8/083001](https://doi.org/10.1088/1367-2630/13/8/083001)
3. Saracco, F., Di Clemente, R., Gabrielli, A. & Squartini, T. (2015). *Randomizing bipartite networks: the case of the World Trade Web.* Scientific Reports **5**, 10595. [doi:10.1038/srep10595](https://doi.org/10.1038/srep10595)
4. Zachary, W. W. (1977). *An information flow model for conflict and fission in small groups.* Journal of Anthropological Research **33**(4), 452–473.
5. NEMtropy (Maximum Entropy Hub, IMT Lucca): [github.com/nicoloval/NEMtropy](https://github.com/nicoloval/NEMtropy) — [PyPI](https://pypi.org/project/NEMtropy/)

## Licence

Coursework project — no specific licence.
